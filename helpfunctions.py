import itertools
import numpy as np
import pandas as pd
from scipy.stats import ttest_ind


def find_edges(list_names_g: list[float], list_values_g: list[str], edge_percents: float):
    """
    The function finds the start and end edges of a graph represented as a DataFrame.

    :param list_names_g: The list of the names of the proteins
    :param list_values_g: The list of the values
    :param edge_percents: The percents for the edges
    :return: Tuple[List[str], List[float], List[str], List[float]]: A tuple containing the start and end edges of the graph and their values.
    """
    if len(list_values_g) == 0:
        return [], []
    if edge_percents <= 0:
        edge_percents = 0
    elif edge_percents >= 100:
        edge_percents = 1
    elif 1 < edge_percents < 100:
        edge_percents /= 100
    num_elements = len(list_names_g)
    num_edges = int(edge_percents * num_elements)

    lower_edges = list_names_g[:num_edges]
    upper_edges = list_names_g[-num_edges:]
    lower_values = list_values_g[:num_edges]
    upper_values = list_values_g[-num_edges:]

    return lower_edges, lower_values, upper_edges, upper_values


def add_reason(sign_changed: bool, Emerging_process: bool, Disappearing_process: bool, p: float, p_value: float) -> str:
    """
    Adds a reason row to a Pandas DataFrame indicating the result of the analysis.

    :param sign_changed: flag that indicate if the sign has changed (from negative to positive or the other way).
    :param Emerging_process: A flag indicating there is only one of the same type and ***.
    :param Disappearing_process: A flag indicating there is only one of the same type and ***.
    :param p: The p-value calculated for the statistical test.
    :param p_value: The p-value threshold for determining significance.
    :return: the reason for the change.
    """
    if sign_changed and (p <= p_value):
        return "P-Value and Sign change"

    elif sign_changed:
        return "Sign change"

    elif Emerging_process:
        return "Emerging process"

    elif Disappearing_process:
        return "Disappearing process"

    elif p <= p_value:
        return "P-Value"


def create_pairs_df(pairs_dict: dict) -> pd.DataFrame:
    """
    This function takes a dictionary of paired DataFrames and concatenates them into a single DataFrame for comparison.

    :param pairs_dict: A dictionary of paired DataFrames.
    :return: A concatenated DataFrame of paired DataFrames for comparison.
    """
    comp_list = []
    for i, df in enumerate(pairs_dict.values()):
        comp_list.append(df)
        if i < len(pairs_dict) - 1:
            comp_list.append(pd.DataFrame(np.nan, index=['-'], columns=df.columns))

    pairs_df = pd.concat(comp_list, sort=False)
    return pairs_df


def pairs_df_to_dict(cell_df: pd.DataFrame, cell_name: str, control_list: list, inhibitor_list: list,
                     fixed_col: str):
    """
    This function convert a Pandas dataframe to a dictionary of pairs of dataframes.

    :param cell_df: The input dataframe of the cell to convert.
    :param cell_name: The name of the cell line to filter the dataframe by.
    :param control_list: The control compound list.
    :param inhibitor_list: The inhibitor compound list.
    :param fixed_col: The name of the column that will remain fixed in each pair. Default is 'time'.
    :return: A dictionary where each key is a tuple representing a pair of compounds, along with optional time points.
             The corresponding value is a Pandas dataframe containing data for that pair.
             The keys are generated by combining cell_name, compound names and time points.
             There are two types of keys:
             (1) Keys for pairs of control_list and inhibitor_list with same fixed_col.
             (2) Keys for pairs of inhibitor_list with itself with different fixed_col.
    """
    full_list = control_list + inhibitor_list

    # Filter the dataframe to only include rows with compound names in the full list
    pairs_df = cell_df.loc[cell_df['compound_name'].isin(full_list)]

    pairs_dict = {}
    # Pairs of control_list and inhibitor_list with same fixed_col
    for i, j in itertools.product(control_list, inhibitor_list):
        for col in pairs_df[fixed_col].unique():
            df_i_j_t = pairs_df.loc[(pairs_df['compound_name'] == i) & (pairs_df[fixed_col] == col)]
            df_j_i_t = pairs_df.loc[(pairs_df['compound_name'] == j) & (pairs_df[fixed_col] == col)]
            if not (df_i_j_t.empty or df_j_i_t.empty):
                pairs_dict[(cell_name, i, j, col)] = pd.concat([df_i_j_t, df_j_i_t])

    # Pairs of inhibitor_list with itself with different fixed_col
    for i in inhibitor_list:
        unique_fixed_col_i = pairs_df.loc[pairs_df['compound_name'] == i, fixed_col].unique()
        for t1, t2 in itertools.combinations(unique_fixed_col_i, 2):
            df_i_t1 = pairs_df.loc[(pairs_df['compound_name'] == i) & (pairs_df[fixed_col] == t1)]
            df_i_t2 = pairs_df.loc[(pairs_df['compound_name'] == i) & (pairs_df[fixed_col] == t2)]
            if not (df_i_t1.empty and df_i_t2.empty):
                pairs_dict[(cell_name, i, i, t1, t2)] = pd.concat([df_i_t1, df_i_t2])

    return pairs_dict


def conTreat_df_to_dict(cell_df: pd.DataFrame, cell_name: str, fixed_col: str = 'time'):
    """
    This function convert a dataframe to a dictionary of pairs of dataframes (control vs treatment).

    :param cell_df: The input dataframe to convert.
    :param cell_name: The name of the cell line to filter the dataframe by.
    :param fixed_col: The name of the column that will remain fixed in each pair. Default is 'time'.
    :return: A dictionary where each key is a tuple representing a pair of compounds, along with optional time points.
             The corresponding value is a Pandas dataframe containing data for that pair.
             The keys are generated by combining cell_name, compound names, and time points.
             The keys represent pairs of the entire control_list and the entire inhibitor_list with the same fixed_col.
    """
    control_types = ['CONTROL', 'DMSO', 'PBS']
    compound_name = cell_df['compound_name'].unique()

    control_list = list(set(compound_name) & set(control_types))
    inhibitor_list = list(set(compound_name) - set(control_list))

    # Filter the dataframe to only include rows with compound names in the control_list and inhibitor_list
    pairs_df = cell_df.loc[cell_df['compound_name'].isin(control_list + inhibitor_list)]

    pairs_dict = {}

    # Create a key representing the pair of control_list and inhibitor_list
    for col in pairs_df[fixed_col].unique():
        df_control = pairs_df.loc[pairs_df['compound_name'].isin(control_list) & (pairs_df[fixed_col] == col)]
        df_inhibitor = pairs_df.loc[pairs_df['compound_name'].isin(inhibitor_list) & (pairs_df[fixed_col] == col)]
        if not (df_control.empty or df_inhibitor.empty):
            key = (cell_name, 'control', 'treatment', col)
            pairs_dict[key] = pd.concat([df_control, df_inhibitor])

    return pairs_dict, control_list, inhibitor_list


def df_to_dict(cell_df: pd.DataFrame, cell_line: str, control_list: list, inhibitor_list: list,
               control_treatment: bool, fixed_col: str):
    """
    This function convert a dataframe to a dictionary.

    :param cell_df: The input dataframe to convert.
    :param cell_line: The name of the cell line.
    :param control_list: The control compound list.
    :param inhibitor_list: The inhibitor compound list.
    :param control_treatment: Flag indicating whether control treatment is applied.
    :param fixed_col: The name of the fixed column.
    :return: A tuple containing three elements:
             pairs_dict - A dictionary where each key represents a pair of compounds, along with optional time points,
             and the corresponding value is a Pandas dataframe containing data for that pair.
             cl - The control list.
             il - The inhibitor list.
    """
    if control_treatment:
        pairs_dict, control_list, inhibitor_list = conTreat_df_to_dict(cell_df, cell_line, fixed_col=fixed_col)
    else:
        pairs_dict = pairs_df_to_dict(cell_df, cell_line, control_list, inhibitor_list, fixed_col=fixed_col)

    return pairs_dict, control_list, inhibitor_list


def get_analysis_columns(sub_df: pd.DataFrame):
    """
    This function retrieves the analysis columns from a subset of a DataFrame.

    :param sub_df: The subset of the DataFrame.
    :return: A list of analysis columns.
    """
    col_names = sub_df.columns.tolist()
    time_col_idx = col_names.index('time')
    analysis_cols = [c for c in col_names[time_col_idx + 1:]]
    return analysis_cols


def get_comparison_data(sub_df: pd.DataFrame, key: tuple, process: str, cl: list, il: list, control_treatment: bool,
                        fixed_col: str):
    """
    This function retrieves the comparison data for a given key from a subset of a DataFrame.

    :param sub_df: The subset of the DataFrame.
    :param key: The key representing the compounds and time points to compare.
    :param process: The name of the process to extract data for.
    :param cl: The control_list.
    :param il: The inhibitor_list.
    :param control_treatment: Flag indicating whether to perform a comparison between CONTROL and TREATMENT as a single unit.
    :param fixed_col: The name of the fixed column.
    :return: A tuple containing two DataFrames representing the data for the first and second conditions.
    """
    if control_treatment:
        df_first = sub_df.loc[(sub_df['compound_name'].isin(cl)) & (sub_df[fixed_col] == key[3]), process]
        df_second = sub_df.loc[(sub_df['compound_name'].isin(il)) & (sub_df[fixed_col] == key[3]), process]
    else:
        if key[1] == key[2]:
            df_first = sub_df.loc[sub_df[fixed_col] == key[3], process]
            df_second = sub_df.loc[sub_df[fixed_col] == key[4], process]
        else:
            df_first = sub_df.loc[sub_df['compound_name'] == key[1], process]
            df_second = sub_df.loc[sub_df['compound_name'] == key[2], process]
    return df_first, df_second


def create_reason_dataframe(sub_df: pd.DataFrame, process: str, p_value: float, df_first: pd.DataFrame,
                            df_second: pd.DataFrame, err_limit_lambda: float):
    """
    This function creates a reason DataFrame based on the comparison of two DataFrames.

    :param sub_df: The original DataFrame.
    :param process: The name of the process being analyzed.
    :param p_value: The threshold p-value for significance.
    :param df_first: The DataFrame for the first condition.
    :param df_second: The DataFrame for the second condition.
    :param err_limit_lambda: The error limit lambda.
    :return: The reason DataFrame if the conditions for significance are met, or None otherwise.
    """
    sign_changed = False
    Emerging_process = False
    Disappearing_process = False
    df_first_mean = df_first.mean()
    df_second_mean = df_second.mean()
    if np.sign(df_first_mean) != np.sign(df_second_mean):
        sign_changed = True
    if df_first.shape[0] == 1 or df_second.shape[0] == 1:
        if (abs(df_first_mean)) < err_limit_lambda < (abs(df_second_mean)):
            Emerging_process = True
        if (abs(df_first_mean)) > err_limit_lambda > (abs(df_second_mean)):
            Disappearing_process = True
        p = p_value + 1
    else:
        t, p = ttest_ind(df_first.tolist(), df_second.tolist())
    if sign_changed or Emerging_process or Disappearing_process or (p <= p_value):
        if (abs(df_first_mean) > err_limit_lambda) or (abs(df_second_mean) > err_limit_lambda):
            add_res = pd.DataFrame(
                [[add_reason(sign_changed, Emerging_process, Disappearing_process, p, p_value)]],
                columns=[process])
            add_res = add_res.rename(index={0: 'Reason'})
            return pd.concat([sub_df[[process]], add_res])
        return None


def create_updated_dataframes(dfs_to_concat: list, averages: dict, sub_df: pd.DataFrame, control_treatment: bool,
                              compound_names: list):
    """
    This function creates updated DataFrames by concatenating them with existing DataFrames.

    :param dfs_to_concat: A list of DataFrames to concatenate.
    :param averages: A dictionary containing average values.
    :param sub_df: The original DataFrame.
    :param control_treatment: Flag indicating whether to perform a comparison between CONTROL and TREATMENT as a single unit.
    :param compound_names: The list of compound names.
    :return: A tuple containing the updated DataFrames and the compound names.
    """
    updated_dfs = []
    for df_col in dfs_to_concat:
        last_row = df_col.iloc[-1].values[0]
        compound_names = sub_df['compound_name'].dropna().unique().tolist()
        if len(compound_names) == 1:
            compound_names.append(compound_names[0])
        if control_treatment:
            index = ["CONTROL AVG", "TREATMENT AVG", "REASON"]
        else:
            index = [compound_names[0] + " AVG", compound_names[1] + " AVG", "REASON"]
        new_col = pd.DataFrame(
            [averages[df_col.columns[0]][0], averages[df_col.columns[0]][1], last_row],
            columns=[df_col.columns[0]],
            index=index)

        updated_dfs.append(new_col)

    return updated_dfs, compound_names


def create_pairs_dataframe_only_avg(sub_df: pd.DataFrame, new_df: pd.DataFrame, control_treatment: bool,
                                    fixed_col: str):
    """
    This function creates a pairs DataFrame containing only average values from a subset of a DataFrame.
    :param sub_df: The original DataFrame.
    :param new_df: The new DataFrame to append.
    :param control_treatment: Flag indicating whether to perform a comparison between CONTROL and TREATMENT as a single unit.
    :param fixed_col: The name of the fixed column.
    :return: The pairs DataFrame containing only average values.
    """
    if control_treatment:
        columns_to_select = ['cell_line_name', fixed_col]
    else:
        columns_to_select = ['cell_line_name', 'compound_name', fixed_col]

    index_first = sub_df[fixed_col].str.extract(r'(\d+)', expand=False).astype(int).idxmin()
    index_second = sub_df[fixed_col].str.extract(r'(\d+)', expand=False).astype(int).idxmax()

    df_without_barcode = pd.DataFrame(columns=columns_to_select)
    df_without_barcode = pd.concat(
        [df_without_barcode] + [pd.DataFrame(columns=df_without_barcode.columns)] * 3,
        ignore_index=True)

    if index_first < index_second:
        df_without_barcode.loc[0] = sub_df.loc[index_first, columns_to_select]
        df_without_barcode.loc[1] = sub_df.loc[index_second, columns_to_select]
    else:
        df_without_barcode.loc[0] = sub_df.loc[index_second, columns_to_select]
        df_without_barcode.loc[1] = sub_df.loc[index_first, columns_to_select]

    compound_names = sub_df['compound_name'].dropna().unique().tolist()
    if len(compound_names) == 1:
        compound_names.append(compound_names[0])

    if df_without_barcode.shape[0] == 2:
        last_row = df_without_barcode.iloc[-1]
        new_row = pd.DataFrame([last_row], columns=df_without_barcode.columns)
        df_without_barcode = pd.concat([df_without_barcode, new_row], ignore_index=True)
    compound_names.append('')

    if control_treatment:
        df_without_barcode.index = ["CONTROL AVG", "TREATMENT AVG", "REASON"]
    else:
        df_without_barcode['compound_name'] = compound_names
        df_without_barcode.index = [compound_names[0] + " AVG", compound_names[1] + " AVG", "REASON"]

    df_without_barcode.loc["REASON"] = np.nan
    return pd.concat([df_without_barcode, new_df], axis=1)


def create_pairs_dataframe_all_data(sub_df: pd.DataFrame, new_df: pd.DataFrame):
    """
    This function creates a pairs DataFrame containing all data from a subset of a DataFrame.
    :param sub_df: The original DataFrame.
    :param new_df: The new DataFrame to append.
    :return: The pairs DataFrame containing all data.
    """
    columns_to_select = ['cell_line_name', 'compound_name', '2D_3D', 'dosage', 'time']
    sub_df_selected = sub_df[columns_to_select].copy()
    sub_df_selected.set_index(sub_df_selected.index.map(lambda x: str(int(x) + 2)), inplace=True)

    new_df_selected = new_df.copy()
    new_df_selected.index = new_df_selected.index.map(
        lambda x: str(int(x) + 2) if x != 'Reason' else x)  # Ignore last row with index label 'REASON'

    return pd.concat([sub_df_selected, new_df_selected], axis=1)
